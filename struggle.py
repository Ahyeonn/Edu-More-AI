import os
import tempfile
from dotenv import load_dotenv
from openai import OpenAI
import noisereduce as nr
import numpy as np
from pydub import AudioSegment

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° (API í‚¤)
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 1. WAV íŒŒì¼ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ëŠ” í•¨ìˆ˜
def denoise_audio(input_file):
    """
    WAV íŒŒì¼ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ê³  ì„ì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # pydubë¥¼ ì‚¬ìš©í•˜ì—¬ WAV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
        audio = AudioSegment.from_wav(input_file)
        
        # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë„˜íŒŒì´(numpy) ë°°ì—´ë¡œ ë³€í™˜
        samples = np.array(audio.get_array_of_samples())
        sample_rate = audio.frame_rate

        # noisereduceë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ì´ì¦ˆ ì œê±°
        reduced_noise_data = nr.reduce_noise(y=samples, sr=sample_rate, stationary=True)
        reduced_audio = audio._spawn(reduced_noise_data.astype(np.int16).tobytes())
        
        # ë…¸ì´ì¦ˆê°€ ì œê±°ëœ ì˜¤ë””ì˜¤ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_wav_path = tempfile.NamedTemporaryFile(suffix=".wav", delete=False).name
        reduced_audio.export(temp_wav_path, format="wav")
        
        print(f"'{input_file}' íŒŒì¼ì˜ ë…¸ì´ì¦ˆê°€ ì œê±°ë˜ì–´ ì„ì‹œ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return temp_wav_path
    
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: '{input_file}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    except Exception as e:
        print(f"ë…¸ì´ì¦ˆ ì œê±° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# 2. ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (STT)
def transcribe_audio(file_path):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ë³€í™˜ ì „ ë…¸ì´ì¦ˆ ì œê±°ê°€ ìë™ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
    """
    temp_file_path = None
    try:
        # ë…¸ì´ì¦ˆ ì œê±° í•¨ìˆ˜ í˜¸ì¶œ
        temp_file_path = denoise_audio(file_path)
        if not temp_file_path:
            return ""

        # ì„ì‹œ íŒŒì¼ì„ ì‚¬ìš©í•´ STT ë³€í™˜ ì§„í–‰
        with open(temp_file_path, "rb") as f:
            transcript = client.audio.transcriptions.create(
                model="gpt-4o-transcribe",
                file=f
            )
        return transcript.text.strip()
        
    finally:
        # ì‘ì—…ì´ ëë‚˜ë©´ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_file_path and os.path.exists(temp_file_path):
            os.remove(temp_file_path)
            print(f"ì„ì‹œ íŒŒì¼ '{temp_file_path}'ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

# 3. í…ìŠ¤íŠ¸ë¥¼ AIì—ê²Œ ì§ˆë¬¸í•˜ê³  ë‹µë³€ì„ ë°›ëŠ” í•¨ìˆ˜ (ChatGPT)
def ask_gpt(question):
    """
    í…ìŠ¤íŠ¸ ì§ˆë¬¸ì„ GPT ëª¨ë¸ì— ë³´ë‚´ê³ , ì´ˆë“±í•™ìƒ ëˆˆë†’ì´ì— ë§ëŠ” ë‹µë³€ì„ ë°›ìŠµë‹ˆë‹¤.
    """
    system_prompt = """
    ì €ëŠ” ì´ˆë“±í•™ìƒë“¤ì„ ê°€ë¥´ì¹˜ëŠ” êµì‚¬ì…ë‹ˆë‹¤. 
    ì˜¤ëŠ˜ì€ ë™ë¬¼ì¹œêµ¬ë“¤ ì•Œì•„ë³´ê¸° ì‹œê°„ì„ ê°€ì§ˆê±°ì—ìš”, ì´ë¦„í•˜ì—¬ "ì‚°ë‚˜ëŠ” ë™ë¬¼ ì¹œêµ¬ë“¤ ì‹œê°„" ì´ì—ìš” 
    ê°œì½”ì›ìˆ­ì´, ë±€, í–„ìŠ¤í„°, ì‚¬ìŠ´, ë„ë§ˆë±€, ì°¸ìƒˆ, ë¬¼ê³ ê¸°, ì˜¤ì§•ì–´ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì„¤ëª…í•˜ëŠ” ì‹œê°„ì„ ê°€ì§ˆê±°ì—ìš”
    ë™ë¬¼ì—ê²Œ ì¸ì‚¬ë¥¼ í•´ë³¼ê¹Œìš” ë¼ê³  í•˜ë©´ ê° ë™ë¬¼ì˜ íŠ¹ì§•ì„ ì•„ì´ ëˆˆë†’ì´ì— ë§ê²Œ ì ì ˆíˆ ì„¤ëª…í•´ì£¼ì„¸ìš” 
    """
    
    response = client.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question}
        ],
        temperature=1.0
    )
    answer = response.choices[0].message.content
    answer = answer.replace('\\n', ' ').replace('\n', ' ')
    return answer

# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---
if __name__ == "__main__":
    # â­ï¸ ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤. 
    # audio_path ë³€ìˆ˜ì— ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì ì–´ì£¼ì„¸ìš”.
    audio_path = "ê°œì½”-ì›ìˆ­ì´.wav"
    
    if os.path.exists(audio_path):
        print(f"'{audio_path}' íŒŒì¼ì˜ STT ë³€í™˜ì„ ì‹œì‘í•©ë‹ˆë‹¤. ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ë¨¼ì € ì§„í–‰í•©ë‹ˆë‹¤...")
        
        # 1. ë…¸ì´ì¦ˆ ì œê±° í›„ STT ë³€í™˜
        transcribed_text = transcribe_audio(audio_path)
        
        if transcribed_text:
            print(f"\nâœ… STT ë³€í™˜ ì™„ë£Œëœ í…ìŠ¤íŠ¸: {transcribed_text}")
            
            # 2. ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ AIì—ê²Œ ì „ë‹¬í•˜ì—¬ ë‹µë³€ ë°›ê¸°
            print("\nğŸ¤– GPT ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘...")
            gpt_response = ask_gpt(transcribed_text)
            
            print(f"\nğŸŒŸ GPTì˜ ë‹µë³€: {gpt_response}")
        else:
            print("STT ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    else:
        print(f"ì˜¤ë¥˜: '{audio_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")